"""
FastAPI Server for Climate Analysis
High-performance async API bridging React frontend with MongoDB
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from datetime import datetime
import logging
import os
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure
import uvicorn
from typing import Optional, List, Dict, Any

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Climate Analysis API",
    description="MapReduce operations on climate data stored in MongoDB",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MongoDB Connection
db = None
mongo_available = False

try:
    from config import MONGO_URI, DATABASE_NAME
    mongo_client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
    mongo_client.server_info()
    db = mongo_client[DATABASE_NAME]
    mongo_available = True
    logger.info(f"✅ Connected to MongoDB: {DATABASE_NAME}")
except ConnectionFailure:
    logger.warning("⚠️  MongoDB not available - using mock data")
    mongo_available = False
except Exception as e:
    logger.warning(f"⚠️  MongoDB connection issue: {e} - using mock data")
    mongo_available = False

# Configuration
UPLOAD_FOLDER = 'uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)


# ============================================================================
# HEALTH & STATUS ENDPOINTS
# ============================================================================

@app.get('/api/health')
async def health():
    """Health check endpoint"""
    return {
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'backend': 'FastAPI with MongoDB',
        'mongo_available': mongo_available
    }


# ============================================================================
# STATISTICS ENDPOINTS
# ============================================================================

@app.get('/api/stats/summary')
async def get_summary_stats():
    """Get summary statistics"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return {
            'total_records': 10500000,
            'dataset_count': 5,
            'avg_temperature': 14.2,
            'last_updated': datetime.now().isoformat(),
            'datasets': {
                'country': {'records': 577000, 'status': 'ready'},
                'city': {'records': 8600000, 'status': 'ready'},
                'state': {'records': 645000, 'status': 'ready'},
                'major_city': {'records': 239000, 'status': 'ready'},
                'global': {'records': 3300, 'status': 'ready'}
            }
        }
    
    try:
        collections_info = {
            'country': 'country_temps',
            'city': 'city_temps',
            'state': 'state_temps',
            'major_city': 'major_city_temps',
            'global': 'global_temps'
        }
        
        datasets = {}
        total_records = 0
        total_temp = 0
        count_for_avg = 0
        
        for key, coll_name in collections_info.items():
            try:
                collection = db[coll_name]
                count = collection.count_documents({})
                datasets[key] = {'records': count, 'status': 'ready'}
                total_records += count
                
                avg_result = list(collection.aggregate([
                    {'$group': {'_id': None, 'avg': {'$avg': '$AverageTemperature'}}}
                ]))
                if avg_result and avg_result[0].get('avg'):
                    total_temp += avg_result[0]['avg'] * count
                    count_for_avg += count
            except Exception as e:
                logger.warning(f"Error getting stats for {coll_name}: {e}")
                datasets[key] = {'records': 0, 'status': 'error'}
        
        avg_temp = round(total_temp / count_for_avg, 2) if count_for_avg > 0 else 0
        
        logger.info(f"✅ Summary: {total_records:,} records, avg temp: {avg_temp}°C")
        return {
            'total_records': total_records,
            'dataset_count': len(datasets),
            'avg_temperature': avg_temp,
            'last_updated': datetime.now().isoformat(),
            'datasets': datasets
        }
    
    except Exception as e:
        logger.error(f"Error fetching summary stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/stats/dataset-info')
async def get_dataset_info():
    """Get detailed dataset information"""
    return {
        'datasets': [
            {
                'name': 'Country',
                'records': 577000,
                'variables': ['dt', 'AverageTemperature', 'Country'],
                'date_range': '1750-2016'
            },
            {
                'name': 'City',
                'records': 8600000,
                'variables': ['dt', 'AverageTemperature', 'City', 'Country', 'Latitude', 'Longitude'],
                'date_range': '1750-2016'
            },
            {
                'name': 'State',
                'records': 645000,
                'variables': ['dt', 'AverageTemperature', 'State', 'Country'],
                'date_range': '1750-2016'
            },
            {
                'name': 'Major City',
                'records': 239000,
                'variables': ['dt', 'AverageTemperature', 'City', 'Country', 'Latitude', 'Longitude'],
                'date_range': '1750-2016'
            },
            {
                'name': 'Global',
                'records': 3300,
                'variables': ['dt', 'AverageTemperature', 'AverageTemperatureUncertainty'],
                'date_range': '1750-2016'
            }
        ]
    }


# ============================================================================
# ANALYTICS ENDPOINTS (MapReduce Results)
# ============================================================================

@app.get('/api/analytics/avg-temp-by-country')
async def get_avg_temp_by_country():
    """Get average temperature by country (MapReduce Op 1)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'Country': 'Burundi', 'average': 23.84, 'min': 19.7, 'max': 26.6, 'count': 3000},
            {'Country': 'Djibouti', 'average': 28.25, 'min': 24.2, 'max': 31.8, 'count': 3100},
            {'Country': 'Mauritania', 'average': 28.91, 'min': 25.1, 'max': 32.4, 'count': 3200},
            {'Country': 'Mali', 'average': 28.83, 'min': 25.0, 'max': 32.2, 'count': 3300},
            {'Country': 'Senegal', 'average': 28.68, 'min': 25.2, 'max': 31.9, 'count': 3100},
        ]

    try:
        # Try to get from cached MapReduce results first
        runs_collection = db['mapreduce_runs']
        latest_run = runs_collection.find_one(sort=[('timestamp', -1)])
        
        if latest_run:
            results_collection = db['mapreduce_results']
            cached_result = results_collection.find_one({
                'run_id': latest_run['_id'],
                'operation': 'avg_temp_by_country'
            })
            if cached_result:
                logger.info(f"✅ Fetched avg temp by country from cache: {len(cached_result['data'])} records")
                return cached_result['data']
        
        # Fall back to live query
        collection = db['country_temps']
        pipeline = [
            {'$group': {
                '_id': '$Country',
                'average': {'$avg': '$AverageTemperature'},
                'min': {'$min': '$AverageTemperature'},
                'max': {'$max': '$AverageTemperature'},
                'count': {'$sum': 1}
            }},
            {'$sort': {'average': -1}},
            {'$limit': 50},
            {'$project': {
                'Country': '$_id',
                'average': {'$round': ['$average', 2]},
                'min': {'$round': ['$min', 2]},
                'max': {'$round': ['$max', 2]},
                'count': 1,
                '_id': 0
            }}
        ]
        
        results = list(collection.aggregate(pipeline))
        logger.info(f"✅ Fetched avg temp by country from live query: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching avg temp by country: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/temp-trends-by-year')
async def get_temp_trends_by_year():
    """Get temperature trends by year (MapReduce Op 2)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'year': 1950, 'average': 13.5, 'min': -50.2, 'max': 48.3, 'count': 50000},
            {'year': 1960, 'average': 13.6, 'min': -51.1, 'max': 49.1, 'count': 75000},
            {'year': 1970, 'average': 13.7, 'min': -50.5, 'max': 49.5, 'count': 150000},
        ]

    try:
        collection = db['country_temps']
        pipeline = [
            {'$addFields': {'year': {'$year': {'$dateFromString': {'dateString': '$dt'}}}}},
            {'$group': {
                '_id': '$year',
                'average': {'$avg': '$AverageTemperature'},
                'min': {'$min': '$AverageTemperature'},
                'max': {'$max': '$AverageTemperature'},
                'count': {'$sum': 1}
            }},
            {'$sort': {'_id': 1}},
            {'$project': {
                'year': '$_id',
                'average': {'$round': ['$average', 2]},
                'min': {'$round': ['$min', 2]},
                'max': {'$round': ['$max', 2]},
                'count': 1,
                '_id': 0
            }}
        ]
        
        results = list(collection.aggregate(pipeline))
        logger.info(f"✅ Fetched temp trends by year: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching temp trends by year: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/seasonal-analysis')
async def get_seasonal_analysis():
    """Get seasonal analysis (MapReduce Op 3)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'season': 'Winter', 'average': 10.2, 'min': -45.0, 'max': 35.5, 'count': 2500000},
            {'season': 'Spring', 'average': 14.1, 'min': -30.0, 'max': 42.0, 'count': 2600000},
            {'season': 'Summer', 'average': 18.5, 'min': -20.0, 'max': 52.0, 'count': 2700000},
            {'season': 'Fall', 'average': 14.8, 'min': -35.0, 'max': 45.0, 'count': 2500000},
        ]

    try:
        collection = db['country_temps']
        pipeline = [
            {'$addFields': {'month': {'$month': {'$dateFromString': {'dateString': '$dt'}}}}},
            {'$addFields': {
                'season': {
                    '$cond': [
                        {'$in': ['$month', [12, 1, 2]]}, 'Winter',
                        {'$cond': [
                            {'$in': ['$month', [3, 4, 5]]}, 'Spring',
                            {'$cond': [
                                {'$in': ['$month', [6, 7, 8]]}, 'Summer',
                                'Fall'
                            ]}
                        ]}
                    ]
                }
            }},
            {'$group': {
                '_id': '$season',
                'average': {'$avg': '$AverageTemperature'},
                'min': {'$min': '$AverageTemperature'},
                'max': {'$max': '$AverageTemperature'},
                'count': {'$sum': 1}
            }},
            {'$project': {
                'season': '$_id',
                'average': {'$round': ['$average', 2]},
                'min': {'$round': ['$min', 2]},
                'max': {'$round': ['$max', 2]},
                'count': 1,
                '_id': 0
            }}
        ]
        
        results = list(collection.aggregate(pipeline))
        logger.info(f"✅ Fetched seasonal analysis: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching seasonal analysis: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/extreme-temps')
async def get_extreme_temps():
    """Get extreme temperatures (MapReduce Op 4)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'dt': '1922-07-21', 'Country': 'Tunisia', 'AverageTemperature': 55.0, 'type': 'Warmest'},
            {'dt': '1954-02-06', 'Country': 'Antarctica', 'AverageTemperature': -89.2, 'type': 'Coldest'},
            {'dt': '2010-07-10', 'Country': 'USA', 'AverageTemperature': 54.0, 'type': 'Warmest'},
        ]

    try:
        collection = db['country_temps']
        
        pipeline_warm = [
            {'$sort': {'AverageTemperature': -1}},
            {'$limit': 5},
            {'$addFields': {'type': 'Warmest'}},
            {'$project': {'dt': 1, 'Country': 1, 'AverageTemperature': {'$round': ['$AverageTemperature', 2]}, 'type': 1, '_id': 0}}
        ]
        
        pipeline_cold = [
            {'$sort': {'AverageTemperature': 1}},
            {'$limit': 5},
            {'$addFields': {'type': 'Coldest'}},
            {'$project': {'dt': 1, 'Country': 1, 'AverageTemperature': {'$round': ['$AverageTemperature', 2]}, 'type': 1, '_id': 0}}
        ]
        
        warmest = list(collection.aggregate(pipeline_warm))
        coldest = list(collection.aggregate(pipeline_cold))
        
        results = warmest + coldest
        logger.info(f"✅ Fetched extreme temps: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching extreme temps: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/decade-analysis')
async def get_decade_analysis():
    """Get decade analysis (MapReduce Op 5)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'decade': 1750, 'average': 12.5, 'count': 10000},
            {'decade': 1800, 'average': 12.8, 'count': 25000},
            {'decade': 1900, 'average': 13.5, 'count': 100000},
            {'decade': 2000, 'average': 14.4, 'count': 500000},
        ]

    try:
        collection = db['country_temps']
        pipeline = [
            {'$addFields': {'year': {'$year': {'$dateFromString': {'dateString': '$dt'}}}}},
            {'$addFields': {'decade': {'$multiply': [{'$floor': {'$divide': ['$year', 10]}}, 10]}}},
            {'$group': {
                '_id': '$decade',
                'average': {'$avg': '$AverageTemperature'},
                'count': {'$sum': 1}
            }},
            {'$sort': {'_id': 1}},
            {'$project': {
                'decade': '$_id',
                'average': {'$round': ['$average', 2]},
                'count': 1,
                '_id': 0
            }}
        ]

        results = list(collection.aggregate(pipeline))
        logger.info(f"✅ Fetched decade analysis: {len(results)} records")
        return results

    except Exception as e:
        logger.error(f"Error fetching decade analysis: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/records-by-country')
async def get_records_by_country():
    """Get records per country (MapReduce Op 6)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'Country': 'Sweden', 'record_count': 35000},
            {'Country': 'France', 'record_count': 32000},
            {'Country': 'Germany', 'record_count': 31000},
            {'Country': 'USA', 'record_count': 30000},
        ]

    try:
        collection = db['country_temps']
        pipeline = [
            {'$group': {
                '_id': '$Country',
                'record_count': {'$sum': 1}
            }},
            {'$sort': {'record_count': -1}},
            {'$limit': 50},
            {'$project': {
                'Country': '$_id',
                'record_count': 1,
                '_id': 0
            }}
        ]
        
        results = list(collection.aggregate(pipeline))
        logger.info(f"✅ Fetched records by country: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching records by country: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# DATA OPERATIONS ENDPOINTS
# ============================================================================

@app.post('/api/preprocess/{dataset_name}')
async def preprocess_data(dataset_name: str):
    """Preprocess dataset"""
    try:
        logger.info(f"Preprocessing {dataset_name}")
        
        return {
            'message': f'{dataset_name} dataset preprocessing started',
            'dataset': dataset_name,
            'status': 'processing',
            'timestamp': datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"Preprocessing error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post('/api/mapreduce/run')
async def run_mapreduce():
    """Run MapReduce operations and store results in MongoDB"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB is not available")
    
    try:
        logger.info("🚀 Starting MapReduce operations - storing results in MongoDB")
        
        # Create results collection if it doesn't exist
        results_collection = db['mapreduce_results']
        
        # Store metadata for this run
        run_id = datetime.now().isoformat()
        run_metadata = {
            '_id': run_id,
            'timestamp': datetime.now(),
            'status': 'completed',
            'operations': []
        }
        
        try:
            # Operation 1: Average Temperature by Country
            avg_temp_pipeline = [
                {'$group': {
                    '_id': '$Country',
                    'average': {'$avg': '$AverageTemperature'},
                    'min': {'$min': '$AverageTemperature'},
                    'max': {'$max': '$AverageTemperature'},
                    'count': {'$sum': 1}
                }},
                {'$sort': {'average': -1}},
                {'$limit': 50},
                {'$project': {
                    'Country': '$_id',
                    'average': {'$round': ['$average', 2]},
                    'min': {'$round': ['$min', 2]},
                    'max': {'$round': ['$max', 2]},
                    'count': 1,
                    '_id': 0
                }}
            ]
            avg_temp_results = list(db['country_temps'].aggregate(avg_temp_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'avg_temp_by_country',
                'timestamp': datetime.now(),
                'data': avg_temp_results,
                'record_count': len(avg_temp_results)
            })
            run_metadata['operations'].append('avg_temp_by_country')
            logger.info(f"✅ Stored avg_temp_by_country: {len(avg_temp_results)} records")
            
            # Operation 2: Temperature Trends by Year
            trends_pipeline = [
                {'$addFields': {'year': {'$year': {'$dateFromString': {'dateString': '$dt'}}}}},
                {'$group': {
                    '_id': '$year',
                    'average': {'$avg': '$AverageTemperature'},
                    'min': {'$min': '$AverageTemperature'},
                    'max': {'$max': '$AverageTemperature'},
                    'count': {'$sum': 1}
                }},
                {'$sort': {'_id': 1}},
                {'$project': {
                    'year': '$_id',
                    'average': {'$round': ['$average', 2]},
                    'min': {'$round': ['$min', 2]},
                    'max': {'$round': ['$max', 2]},
                    'count': 1,
                    '_id': 0
                }}
            ]
            trends_results = list(db['country_temps'].aggregate(trends_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'temp_trends_by_year',
                'timestamp': datetime.now(),
                'data': trends_results,
                'record_count': len(trends_results)
            })
            run_metadata['operations'].append('temp_trends_by_year')
            logger.info(f"✅ Stored temp_trends_by_year: {len(trends_results)} records")
            
            # Operation 3: Seasonal Analysis
            seasonal_pipeline = [
                {'$addFields': {'month': {'$month': {'$dateFromString': {'dateString': '$dt'}}}}},
                {'$addFields': {
                    'season': {
                        '$cond': [
                            {'$in': ['$month', [12, 1, 2]]}, 'Winter',
                            {'$cond': [
                                {'$in': ['$month', [3, 4, 5]]}, 'Spring',
                                {'$cond': [
                                    {'$in': ['$month', [6, 7, 8]]}, 'Summer',
                                    'Fall'
                                ]}
                            ]}
                        ]
                    }
                }},
                {'$group': {
                    '_id': '$season',
                    'average': {'$avg': '$AverageTemperature'},
                    'min': {'$min': '$AverageTemperature'},
                    'max': {'$max': '$AverageTemperature'},
                    'count': {'$sum': 1}
                }},
                {'$project': {
                    'season': '$_id',
                    'average': {'$round': ['$average', 2]},
                    'min': {'$round': ['$min', 2]},
                    'max': {'$round': ['$max', 2]},
                    'count': 1,
                    '_id': 0
                }}
            ]
            seasonal_results = list(db['country_temps'].aggregate(seasonal_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'seasonal_analysis',
                'timestamp': datetime.now(),
                'data': seasonal_results,
                'record_count': len(seasonal_results)
            })
            run_metadata['operations'].append('seasonal_analysis')
            logger.info(f"✅ Stored seasonal_analysis: {len(seasonal_results)} records")
            
            # Operation 4: Extreme Temperatures
            extreme_warm = list(db['country_temps'].aggregate([
                {'$sort': {'AverageTemperature': -1}},
                {'$limit': 5},
                {'$addFields': {'type': 'Warmest'}},
                {'$project': {'dt': 1, 'Country': 1, 'AverageTemperature': {'$round': ['$AverageTemperature', 2]}, 'type': 1, '_id': 0}}
            ]))
            extreme_cold = list(db['country_temps'].aggregate([
                {'$sort': {'AverageTemperature': 1}},
                {'$limit': 5},
                {'$addFields': {'type': 'Coldest'}},
                {'$project': {'dt': 1, 'Country': 1, 'AverageTemperature': {'$round': ['$AverageTemperature', 2]}, 'type': 1, '_id': 0}}
            ]))
            extreme_results = extreme_warm + extreme_cold
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'extreme_temps',
                'timestamp': datetime.now(),
                'data': extreme_results,
                'record_count': len(extreme_results)
            })
            run_metadata['operations'].append('extreme_temps')
            logger.info(f"✅ Stored extreme_temps: {len(extreme_results)} records")
            
            # Operation 5: Decade Analysis
            decade_pipeline = [
                {'$addFields': {'year': {'$year': {'$dateFromString': {'dateString': '$dt'}}}}},
                {'$addFields': {'decade': {'$multiply': [{'$floor': {'$divide': ['$year', 10]}}, 10]}}},
                {'$group': {
                    '_id': '$decade',
                    'average': {'$avg': '$AverageTemperature'},
                    'count': {'$sum': 1}
                }},
                {'$sort': {'_id': 1}},
                {'$project': {
                    'decade': '$_id',
                    'average': {'$round': ['$average', 2]},
                    'count': 1,
                    '_id': 0
                }}
            ]
            decade_results = list(db['country_temps'].aggregate(decade_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'decade_analysis',
                'timestamp': datetime.now(),
                'data': decade_results,
                'record_count': len(decade_results)
            })
            run_metadata['operations'].append('decade_analysis')
            logger.info(f"✅ Stored decade_analysis: {len(decade_results)} records")
            
            # Operation 6: Records per Country
            records_pipeline = [
                {'$group': {
                    '_id': '$Country',
                    'record_count': {'$sum': 1}
                }},
                {'$sort': {'record_count': -1}},
                {'$limit': 50},
                {'$project': {
                    'Country': '$_id',
                    'record_count': 1,
                    '_id': 0
                }}
            ]
            records_results = list(db['country_temps'].aggregate(records_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'records_by_country',
                'timestamp': datetime.now(),
                'data': records_results,
                'record_count': len(records_results)
            })
            run_metadata['operations'].append('records_by_country')
            logger.info(f"✅ Stored records_by_country: {len(records_results)} records")
            
        except Exception as e:
            logger.error(f"Error storing MapReduce results: {e}")
            run_metadata['status'] = 'error'
            run_metadata['error'] = str(e)
        
        # Store run metadata
        db['mapreduce_runs'].insert_one(run_metadata)
        
        logger.info(f"✅ All MapReduce operations completed and stored with ID: {run_id}")
        
        return {
            'message': 'MapReduce operations completed and stored in MongoDB',
            'run_id': run_id,
            'operations': 6,
            'status': 'completed',
            'timestamp': datetime.now().isoformat(),
            'operations_list': run_metadata['operations']
        }

    except Exception as e:
        logger.error(f"MapReduce error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/mapreduce/status')
async def mapreduce_status():
    """Get MapReduce operation status and retrieve latest results"""
    if not mongo_available or db is None:
        return {
            'status': 'completed',
            'operations': 6,
            'completed': 6,
            'failed': 0,
            'timestamp': datetime.now().isoformat()
        }
    
    try:
        # Get latest run
        runs_collection = db['mapreduce_runs']
        latest_run = runs_collection.find_one(sort=[('timestamp', -1)])
        
        if not latest_run:
            return {
                'status': 'no_data',
                'message': 'No MapReduce results found yet. Run operations first.',
                'timestamp': datetime.now().isoformat()
            }
        
        run_id = latest_run['_id']
        results_collection = db['mapreduce_results']
        
        # Retrieve all results for this run
        stored_results = list(results_collection.find({'run_id': run_id}))
        
        return {
            'status': 'completed',
            'run_id': run_id,
            'timestamp': latest_run.get('timestamp', datetime.now()).isoformat(),
            'operations': len(latest_run.get('operations', [])),
            'completed': len(latest_run.get('operations', [])),
            'failed': 0,
            'results_stored': {op['operation']: op['record_count'] for op in stored_results},
            'message': f'Latest MapReduce run stored with {len(stored_results)} result sets'
        }
    
    except Exception as e:
        logger.error(f"Error retrieving MapReduce status: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/mapreduce/results/{operation}')
async def get_mapreduce_result(operation: str):
    """Get stored MapReduce result for a specific operation"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB not available")
    
    try:
        # Get latest run
        runs_collection = db['mapreduce_runs']
        latest_run = runs_collection.find_one(sort=[('timestamp', -1)])
        
        if not latest_run:
            raise HTTPException(status_code=404, detail="No MapReduce results found")
        
        run_id = latest_run['_id']
        results_collection = db['mapreduce_results']
        
        # Retrieve specific operation result
        result = results_collection.find_one({
            'run_id': run_id,
            'operation': operation
        })
        
        if not result:
            raise HTTPException(status_code=404, detail=f"Operation '{operation}' not found in results")
        
        logger.info(f"✅ Retrieved stored result for operation: {operation}")
        return result['data']
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving MapReduce result: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/mapreduce/history')
async def get_mapreduce_history():
    """Get history of all MapReduce runs"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB not available")
    
    try:
        runs_collection = db['mapreduce_runs']
        
        # Get last 10 runs
        history = list(runs_collection.find().sort('timestamp', -1).limit(10))
        
        # Convert to serializable format
        history_data = []
        for run in history:
            history_data.append({
                'run_id': run['_id'],
                'timestamp': run.get('timestamp', '').isoformat() if hasattr(run.get('timestamp'), 'isoformat') else str(run.get('timestamp')),
                'status': run.get('status', 'unknown'),
                'operations_count': len(run.get('operations', [])),
                'operations': run.get('operations', [])
            })
        
        logger.info(f"✅ Retrieved MapReduce history: {len(history_data)} runs")
        return history_data
    
    except Exception as e:
        logger.error(f"Error retrieving MapReduce history: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# CSV UPLOAD TO MONGODB AS JSON
# ============================================================================

@app.post('/api/upload/csv')
async def upload_csv(file: UploadFile = File(...)):
    """Upload CSV file and store as JSON in MongoDB collection"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB not available")
    
    import csv
    from io import StringIO
    import re
    
    try:
        # Read file content
        content = await file.read()
        text = content.decode('utf-8')
        
        # Validate CSV format
        csv_reader = csv.DictReader(StringIO(text))
        if not csv_reader.fieldnames:
            raise ValueError("CSV file is empty or invalid")
        
        # Generate collection name from filename (remove extension, lowercase, replace spaces)
        file_name = file.filename.rsplit('.', 1)[0]
        collection_name = f"uploaded_{re.sub(r'[^a-z0-9_]', '_', file_name.lower())}"
        
        logger.info(f"📊 Processing CSV: {file.filename} → MongoDB collection: {collection_name}")
        
        # Parse CSV and convert to documents
        collection = db[collection_name]
        documents = []
        row_count = 0
        
        for row in csv_reader:
            # Clean and convert data types
            doc = {}
            for key, value in row.items():
                if key and value:  # Skip empty keys/values
                    # Try to convert to appropriate types
                    if value.lower() in ['true', 'false']:
                        doc[key] = value.lower() == 'true'
                    elif value.lower() in ['null', 'none', '']:
                        doc[key] = None
                    else:
                        try:
                            # Try float conversion
                            if '.' in value:
                                doc[key] = float(value)
                            else:
                                # Try int conversion
                                doc[key] = int(value)
                        except ValueError:
                            # Keep as string if not numeric
                            doc[key] = value
            
            if doc:  # Only add non-empty documents
                documents.append(doc)
                row_count += 1
        
        if not documents:
            raise ValueError("No valid data found in CSV file")
        
        # Insert documents into MongoDB
        result = collection.insert_many(documents)
        
        # Create index on common fields if they exist
        if '_id' not in collection.index_information():
            collection.create_index('_id')
        
        # Get sample data
        sample_docs = list(collection.find().limit(5))
        
        # Store metadata
        metadata = {
            'collection_name': collection_name,
            'original_file': file.filename,
            'upload_date': datetime.now(),
            'document_count': len(result.inserted_ids),
            'fields': list(documents[0].keys()) if documents else []
        }
        
        metadata_collection = db['upload_metadata']
        metadata_collection.insert_one(metadata)
        
        logger.info(f"✅ Uploaded {len(result.inserted_ids):,} documents to '{collection_name}'")
        
        return {
            'success': True,
            'collection_name': collection_name,
            'document_count': len(result.inserted_ids),
            'fields': list(documents[0].keys()) if documents else [],
            'sample_data': sample_docs,
            'message': f"Successfully uploaded {len(result.inserted_ids):,} records to collection '{collection_name}'"
        }
    
    except Exception as e:
        logger.error(f"Error uploading CSV: {e}")
        raise HTTPException(status_code=400, detail=f"Error uploading CSV: {str(e)}")


@app.get('/api/uploaded-collections')
async def get_uploaded_collections():
    """Get list of all uploaded collections"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB not available")
    
    try:
        metadata_collection = db['upload_metadata']
        uploads = list(metadata_collection.find().sort('upload_date', -1))
        
        # Convert ObjectId to string for JSON serialization
        result = []
        for upload in uploads:
            result.append({
                'collection_name': upload['collection_name'],
                'original_file': upload['original_file'],
                'upload_date': upload['upload_date'].isoformat() if hasattr(upload['upload_date'], 'isoformat') else str(upload['upload_date']),
                'document_count': upload['document_count'],
                'fields': upload.get('fields', [])
            })
        
        logger.info(f"✅ Retrieved {len(result)} uploaded collections")
        return result
    
    except Exception as e:
        logger.error(f"Error retrieving uploaded collections: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/collection/{collection_name}')
async def get_collection_data(collection_name: str, limit: int = 10):
    """Get data from a specific collection (uploaded or default)"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB not available")
    
    try:
        collection = db[collection_name]
        documents = list(collection.find().limit(limit))
        
        # Convert ObjectId to string
        for doc in documents:
            if '_id' in doc:
                doc['_id'] = str(doc['_id'])
        
        total_count = collection.count_documents({})
        
        logger.info(f"✅ Retrieved {len(documents)} documents from collection: {collection_name}")
        return {
            'collection_name': collection_name,
            'document_count': total_count,
            'documents': documents,
            'limit': limit
        }
    
    except Exception as e:
        logger.error(f"Error retrieving collection data: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post('/api/mapreduce/run-on-collection')
async def run_mapreduce_on_collection(collection_name: str):
    """Run MapReduce operations on a specific uploaded collection"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB not available")
    
    try:
        collection = db[collection_name]
        
        # Check if collection exists and has data
        doc_count = collection.count_documents({})
        if doc_count == 0:
            raise ValueError(f"Collection '{collection_name}' is empty")
        
        logger.info(f"🔄 Running MapReduce on collection: {collection_name} ({doc_count:,} documents)")
        
        # Store metadata
        runs_collection = db['mapreduce_runs']
        run_id = datetime.now().isoformat()
        
        run_metadata = {
            '_id': run_id,
            'timestamp': datetime.now(),
            'source_collection': collection_name,
            'source_document_count': doc_count,
            'operations': []
        }
        
        results_collection = db['mapreduce_results']
        operations_completed = []
        
        # Define MapReduce operations adapted for uploaded collection
        # These are simplified versions that work with any temperature-like data
        
        # Operation 1: Average by main grouping field
        main_fields = ['Country', 'City', 'State', 'Region', 'Location', 'name', 'category']
        group_field = next((f for f in main_fields if f in collection.index_information() or collection.count_documents({f: {'$exists': True}}) > 0), 'category')
        
        try:
            agg_result = list(collection.aggregate([
                {'$group': {
                    '_id': f'${group_field}' if group_field else None,
                    'average': {'$avg': '$AverageTemperature'} if collection.count_documents({'AverageTemperature': {'$exists': True}}) > 0 else {'$avg': '$temperature'},
                    'count': {'$sum': 1}
                }},
                {'$sort': {'average': -1}},
                {'$limit': 10}
            ]))
            
            op_name = 'avg_temperature'
            operation_result = {
                'run_id': run_id,
                'operation': op_name,
                'record_count': len(agg_result),
                'data': agg_result,
                'timestamp': datetime.now()
            }
            results_collection.insert_one(operation_result)
            operations_completed.append(op_name)
            logger.info(f"✅ Operation '{op_name}' completed: {len(agg_result)} results")
        except Exception as e:
            logger.warning(f"⚠️  Operation 'avg_temperature' failed: {e}")
        
        # Operation 2: Record count by time period (if date field exists)
        try:
            date_fields = ['dt', 'date', 'Date', 'timestamp', 'Timestamp']
            date_field = next((f for f in date_fields if collection.count_documents({f: {'$exists': True}}) > 0), None)
            
            if date_field:
                agg_result = list(collection.aggregate([
                    {'$group': {
                        '_id': f'${date_field}',
                        'count': {'$sum': 1}
                    }},
                    {'$sort': {'_id': -1}},
                    {'$limit': 10}
                ]))
                
                op_name = 'records_by_date'
                operation_result = {
                    'run_id': run_id,
                    'operation': op_name,
                    'record_count': len(agg_result),
                    'data': agg_result,
                    'timestamp': datetime.now()
                }
                results_collection.insert_one(operation_result)
                operations_completed.append(op_name)
                logger.info(f"✅ Operation '{op_name}' completed: {len(agg_result)} results")
        except Exception as e:
            logger.warning(f"⚠️  Operation 'records_by_date' failed: {e}")
        
        # Operation 3: Temperature statistics
        try:
            temp_fields = ['AverageTemperature', 'temperature', 'avg_temp', 'temp']
            temp_field = next((f for f in temp_fields if collection.count_documents({f: {'$exists': True}}) > 0), None)
            
            if temp_field:
                agg_result = list(collection.aggregate([
                    {'$group': {
                        '_id': None,
                        'avg_temp': {'$avg': f'${temp_field}'},
                        'min_temp': {'$min': f'${temp_field}'},
                        'max_temp': {'$max': f'${temp_field}'},
                        'total_records': {'$sum': 1}
                    }}
                ]))
                
                op_name = 'temperature_stats'
                operation_result = {
                    'run_id': run_id,
                    'operation': op_name,
                    'record_count': 1,
                    'data': agg_result,
                    'timestamp': datetime.now()
                }
                results_collection.insert_one(operation_result)
                operations_completed.append(op_name)
                logger.info(f"✅ Operation '{op_name}' completed")
        except Exception as e:
            logger.warning(f"⚠️  Operation 'temperature_stats' failed: {e}")
        
        # Update run metadata
        run_metadata['operations'] = operations_completed
        runs_collection.insert_one(run_metadata)
        
        logger.info(f"✅ MapReduce completed on '{collection_name}': {len(operations_completed)} operations")
        
        return {
            'success': True,
            'message': f"MapReduce completed on collection '{collection_name}'",
            'collection_name': collection_name,
            'source_document_count': doc_count,
            'operations_completed': len(operations_completed),
            'operations': operations_completed,
            'run_id': run_id,
            'timestamp': datetime.now().isoformat()
        }
    
    except Exception as e:
        logger.error(f"MapReduce error on custom collection: {str(e)}")
        raise HTTPException(status_code=500, detail=f"MapReduce error: {str(e)}")


# ============================================================================
# MAIN
# ============================================================================


if __name__ == '__main__':
    logger.info("=" * 70)
    logger.info("🚀 Climate Analysis FastAPI Server")
    logger.info("=" * 70)
    logger.info(f"Frontend: http://localhost:3000")
    logger.info(f"API: http://localhost:5001")
    logger.info(f"Docs: http://localhost:5001/docs")
    logger.info(f"MongoDB: {'✅ Connected' if mongo_available else '⚠️  Using Mock Data'}")
    logger.info("=" * 70)
    
    uvicorn.run(app, host="0.0.0.0", port=5001, reload=False, log_level="info")

