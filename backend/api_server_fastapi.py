"""
FastAPI Server for Climate Analysis
High-performance async API bridging React frontend with MongoDB
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from datetime import datetime
import logging
import os
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure
import uvicorn
from typing import Optional, List, Dict, Any

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Climate Analysis API",
    description="MapReduce operations on climate data stored in MongoDB",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MongoDB Connection
db = None
mongo_available = False

try:
    from config import MONGO_URI, DATABASE_NAME
    mongo_client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
    mongo_client.server_info()
    db = mongo_client[DATABASE_NAME]
    mongo_available = True
    logger.info(f"‚úÖ Connected to MongoDB: {DATABASE_NAME}")
except ConnectionFailure:
    logger.warning("‚ö†Ô∏è  MongoDB not available - using mock data")
    mongo_available = False
except Exception as e:
    logger.warning(f"‚ö†Ô∏è  MongoDB connection issue: {e} - using mock data")
    mongo_available = False

# Configuration
UPLOAD_FOLDER = 'uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)


# ============================================================================
# HEALTH & STATUS ENDPOINTS
# ============================================================================

@app.get('/api/health')
async def health():
    """Health check endpoint"""
    return {
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'backend': 'FastAPI with MongoDB',
        'mongo_available': mongo_available
    }


# ============================================================================
# STATISTICS ENDPOINTS
# ============================================================================

@app.get('/api/stats/summary')
async def get_summary_stats():
    """Get summary statistics"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return {
            'total_records': 10500000,
            'dataset_count': 5,
            'avg_temperature': 14.2,
            'last_updated': datetime.now().isoformat(),
            'datasets': {
                'country': {'records': 577000, 'status': 'ready'},
                'city': {'records': 8600000, 'status': 'ready'},
                'state': {'records': 645000, 'status': 'ready'},
                'major_city': {'records': 239000, 'status': 'ready'},
                'global': {'records': 3300, 'status': 'ready'}
            }
        }
    
    try:
        collections_info = {
            'country': 'country_temps',
            'city': 'city_temps',
            'state': 'state_temps',
            'major_city': 'major_city_temps',
            'global': 'global_temps'
        }
        
        datasets = {}
        total_records = 0
        total_temp = 0
        count_for_avg = 0
        
        for key, coll_name in collections_info.items():
            try:
                collection = db[coll_name]
                count = collection.count_documents({})
                datasets[key] = {'records': count, 'status': 'ready'}
                total_records += count
                
                avg_result = list(collection.aggregate([
                    {'$group': {'_id': None, 'avg': {'$avg': '$AverageTemperature'}}}
                ]))
                if avg_result and avg_result[0].get('avg'):
                    total_temp += avg_result[0]['avg'] * count
                    count_for_avg += count
            except Exception as e:
                logger.warning(f"Error getting stats for {coll_name}: {e}")
                datasets[key] = {'records': 0, 'status': 'error'}
        
        avg_temp = round(total_temp / count_for_avg, 2) if count_for_avg > 0 else 0
        
        logger.info(f"‚úÖ Summary: {total_records:,} records, avg temp: {avg_temp}¬∞C")
        return {
            'total_records': total_records,
            'dataset_count': len(datasets),
            'avg_temperature': avg_temp,
            'last_updated': datetime.now().isoformat(),
            'datasets': datasets
        }
    
    except Exception as e:
        logger.error(f"Error fetching summary stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/stats/dataset-info')
async def get_dataset_info():
    """Get detailed dataset information"""
    return {
        'datasets': [
            {
                'name': 'Country',
                'records': 577000,
                'variables': ['dt', 'AverageTemperature', 'Country'],
                'date_range': '1750-2016'
            },
            {
                'name': 'City',
                'records': 8600000,
                'variables': ['dt', 'AverageTemperature', 'City', 'Country', 'Latitude', 'Longitude'],
                'date_range': '1750-2016'
            },
            {
                'name': 'State',
                'records': 645000,
                'variables': ['dt', 'AverageTemperature', 'State', 'Country'],
                'date_range': '1750-2016'
            },
            {
                'name': 'Major City',
                'records': 239000,
                'variables': ['dt', 'AverageTemperature', 'City', 'Country', 'Latitude', 'Longitude'],
                'date_range': '1750-2016'
            },
            {
                'name': 'Global',
                'records': 3300,
                'variables': ['dt', 'AverageTemperature', 'AverageTemperatureUncertainty'],
                'date_range': '1750-2016'
            }
        ]
    }


# ============================================================================
# ANALYTICS ENDPOINTS (MapReduce Results)
# ============================================================================

@app.get('/api/analytics/avg-temp-by-country')
async def get_avg_temp_by_country():
    """Get average temperature by country (MapReduce Op 1)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'Country': 'Burundi', 'average': 23.84, 'min': 19.7, 'max': 26.6, 'count': 3000},
            {'Country': 'Djibouti', 'average': 28.25, 'min': 24.2, 'max': 31.8, 'count': 3100},
            {'Country': 'Mauritania', 'average': 28.91, 'min': 25.1, 'max': 32.4, 'count': 3200},
            {'Country': 'Mali', 'average': 28.83, 'min': 25.0, 'max': 32.2, 'count': 3300},
            {'Country': 'Senegal', 'average': 28.68, 'min': 25.2, 'max': 31.9, 'count': 3100},
        ]

    try:
        # Try to get from cached MapReduce results first
        runs_collection = db['mapreduce_runs']
        latest_run = runs_collection.find_one(sort=[('timestamp', -1)])
        
        if latest_run:
            results_collection = db['mapreduce_results']
            cached_result = results_collection.find_one({
                'run_id': latest_run['_id'],
                'operation': 'avg_temp_by_country'
            })
            if cached_result:
                logger.info(f"‚úÖ Fetched avg temp by country from cache: {len(cached_result['data'])} records")
                return cached_result['data']
        
        # Fall back to live query
        collection = db['country_temps']
        pipeline = [
            {'$group': {
                '_id': '$Country',
                'average': {'$avg': '$AverageTemperature'},
                'min': {'$min': '$AverageTemperature'},
                'max': {'$max': '$AverageTemperature'},
                'count': {'$sum': 1}
            }},
            {'$sort': {'average': -1}},
            {'$limit': 50},
            {'$project': {
                'Country': '$_id',
                'average': {'$round': ['$average', 2]},
                'min': {'$round': ['$min', 2]},
                'max': {'$round': ['$max', 2]},
                'count': 1,
                '_id': 0
            }}
        ]
        
        results = list(collection.aggregate(pipeline))
        logger.info(f"‚úÖ Fetched avg temp by country from live query: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching avg temp by country: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/temp-trends-by-year')
async def get_temp_trends_by_year():
    """Get temperature trends by year (MapReduce Op 2)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'year': 1950, 'average': 13.5, 'min': -50.2, 'max': 48.3, 'count': 50000},
            {'year': 1960, 'average': 13.6, 'min': -51.1, 'max': 49.1, 'count': 75000},
            {'year': 1970, 'average': 13.7, 'min': -50.5, 'max': 49.5, 'count': 150000},
        ]

    try:
        collection = db['country_temps']
        pipeline = [
            {'$addFields': {'year': {'$year': {'$dateFromString': {'dateString': '$dt'}}}}},
            {'$group': {
                '_id': '$year',
                'average': {'$avg': '$AverageTemperature'},
                'min': {'$min': '$AverageTemperature'},
                'max': {'$max': '$AverageTemperature'},
                'count': {'$sum': 1}
            }},
            {'$sort': {'_id': 1}},
            {'$project': {
                'year': '$_id',
                'average': {'$round': ['$average', 2]},
                'min': {'$round': ['$min', 2]},
                'max': {'$round': ['$max', 2]},
                'count': 1,
                '_id': 0
            }}
        ]
        
        results = list(collection.aggregate(pipeline))
        logger.info(f"‚úÖ Fetched temp trends by year: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching temp trends by year: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/seasonal-analysis')
async def get_seasonal_analysis():
    """Get seasonal analysis (MapReduce Op 3)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'season': 'Winter', 'average': 10.2, 'min': -45.0, 'max': 35.5, 'count': 2500000},
            {'season': 'Spring', 'average': 14.1, 'min': -30.0, 'max': 42.0, 'count': 2600000},
            {'season': 'Summer', 'average': 18.5, 'min': -20.0, 'max': 52.0, 'count': 2700000},
            {'season': 'Fall', 'average': 14.8, 'min': -35.0, 'max': 45.0, 'count': 2500000},
        ]

    try:
        collection = db['country_temps']
        pipeline = [
            {'$addFields': {'month': {'$month': {'$dateFromString': {'dateString': '$dt'}}}}},
            {'$addFields': {
                'season': {
                    '$cond': [
                        {'$in': ['$month', [12, 1, 2]]}, 'Winter',
                        {'$cond': [
                            {'$in': ['$month', [3, 4, 5]]}, 'Spring',
                            {'$cond': [
                                {'$in': ['$month', [6, 7, 8]]}, 'Summer',
                                'Fall'
                            ]}
                        ]}
                    ]
                }
            }},
            {'$group': {
                '_id': '$season',
                'average': {'$avg': '$AverageTemperature'},
                'min': {'$min': '$AverageTemperature'},
                'max': {'$max': '$AverageTemperature'},
                'count': {'$sum': 1}
            }},
            {'$project': {
                'season': '$_id',
                'average': {'$round': ['$average', 2]},
                'min': {'$round': ['$min', 2]},
                'max': {'$round': ['$max', 2]},
                'count': 1,
                '_id': 0
            }}
        ]
        
        results = list(collection.aggregate(pipeline))
        logger.info(f"‚úÖ Fetched seasonal analysis: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching seasonal analysis: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/extreme-temps')
async def get_extreme_temps():
    """Get extreme temperatures (MapReduce Op 4)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'dt': '1922-07-21', 'Country': 'Tunisia', 'AverageTemperature': 55.0, 'type': 'Warmest'},
            {'dt': '1954-02-06', 'Country': 'Antarctica', 'AverageTemperature': -89.2, 'type': 'Coldest'},
            {'dt': '2010-07-10', 'Country': 'USA', 'AverageTemperature': 54.0, 'type': 'Warmest'},
        ]

    try:
        collection = db['country_temps']
        
        pipeline_warm = [
            {'$sort': {'AverageTemperature': -1}},
            {'$limit': 5},
            {'$addFields': {'type': 'Warmest'}},
            {'$project': {'dt': 1, 'Country': 1, 'AverageTemperature': {'$round': ['$AverageTemperature', 2]}, 'type': 1, '_id': 0}}
        ]
        
        pipeline_cold = [
            {'$sort': {'AverageTemperature': 1}},
            {'$limit': 5},
            {'$addFields': {'type': 'Coldest'}},
            {'$project': {'dt': 1, 'Country': 1, 'AverageTemperature': {'$round': ['$AverageTemperature', 2]}, 'type': 1, '_id': 0}}
        ]
        
        warmest = list(collection.aggregate(pipeline_warm))
        coldest = list(collection.aggregate(pipeline_cold))
        
        results = warmest + coldest
        logger.info(f"‚úÖ Fetched extreme temps: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching extreme temps: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/decade-analysis')
async def get_decade_analysis():
    """Get decade analysis (MapReduce Op 5)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'decade': 1750, 'average': 12.5, 'count': 10000},
            {'decade': 1800, 'average': 12.8, 'count': 25000},
            {'decade': 1900, 'average': 13.5, 'count': 100000},
            {'decade': 2000, 'average': 14.4, 'count': 500000},
        ]

    try:
        collection = db['country_temps']
        pipeline = [
            {'$addFields': {'year': {'$year': {'$dateFromString': {'dateString': '$dt'}}}}},
            {'$addFields': {'decade': {'$multiply': [{'$floor': {'$divide': ['$year', 10]}}, 10]}}},
            {'$group': {
                '_id': '$decade',
                'average': {'$avg': '$AverageTemperature'},
                'count': {'$sum': 1}
            }},
            {'$sort': {'_id': 1}},
            {'$project': {
                'decade': '$_id',
                'average': {'$round': ['$average', 2]},
                'count': 1,
                '_id': 0
            }}
        ]

        results = list(collection.aggregate(pipeline))
        logger.info(f"‚úÖ Fetched decade analysis: {len(results)} records")
        return results

    except Exception as e:
        logger.error(f"Error fetching decade analysis: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/analytics/records-by-country')
async def get_records_by_country():
    """Get records per country (MapReduce Op 6)"""
    if not mongo_available or db is None:
        logger.warning("MongoDB not available, returning mock data")
        return [
            {'Country': 'Sweden', 'record_count': 35000},
            {'Country': 'France', 'record_count': 32000},
            {'Country': 'Germany', 'record_count': 31000},
            {'Country': 'USA', 'record_count': 30000},
        ]

    try:
        collection = db['country_temps']
        pipeline = [
            {'$group': {
                '_id': '$Country',
                'record_count': {'$sum': 1}
            }},
            {'$sort': {'record_count': -1}},
            {'$limit': 50},
            {'$project': {
                'Country': '$_id',
                'record_count': 1,
                '_id': 0
            }}
        ]
        
        results = list(collection.aggregate(pipeline))
        logger.info(f"‚úÖ Fetched records by country: {len(results)} records")
        return results
    
    except Exception as e:
        logger.error(f"Error fetching records by country: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# DATA OPERATIONS ENDPOINTS
# ============================================================================

@app.post('/api/preprocess/{dataset_name}')
async def preprocess_data(dataset_name: str):
    """Preprocess dataset"""
    try:
        logger.info(f"Preprocessing {dataset_name}")
        
        return {
            'message': f'{dataset_name} dataset preprocessing started',
            'dataset': dataset_name,
            'status': 'processing',
            'timestamp': datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"Preprocessing error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post('/api/mapreduce/run')
async def run_mapreduce():
    """Run MapReduce operations and store results in MongoDB"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB is not available")
    
    try:
        logger.info("üöÄ Starting MapReduce operations - storing results in MongoDB")
        
        # Create results collection if it doesn't exist
        results_collection = db['mapreduce_results']
        
        # Store metadata for this run
        run_id = datetime.now().isoformat()
        run_metadata = {
            '_id': run_id,
            'timestamp': datetime.now(),
            'status': 'completed',
            'operations': []
        }
        
        try:
            # Operation 1: Average Temperature by Country
            avg_temp_pipeline = [
                {'$group': {
                    '_id': '$Country',
                    'average': {'$avg': '$AverageTemperature'},
                    'min': {'$min': '$AverageTemperature'},
                    'max': {'$max': '$AverageTemperature'},
                    'count': {'$sum': 1}
                }},
                {'$sort': {'average': -1}},
                {'$limit': 50},
                {'$project': {
                    'Country': '$_id',
                    'average': {'$round': ['$average', 2]},
                    'min': {'$round': ['$min', 2]},
                    'max': {'$round': ['$max', 2]},
                    'count': 1,
                    '_id': 0
                }}
            ]
            avg_temp_results = list(db['country_temps'].aggregate(avg_temp_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'avg_temp_by_country',
                'timestamp': datetime.now(),
                'data': avg_temp_results,
                'record_count': len(avg_temp_results)
            })
            run_metadata['operations'].append('avg_temp_by_country')
            logger.info(f"‚úÖ Stored avg_temp_by_country: {len(avg_temp_results)} records")
            
            # Operation 2: Temperature Trends by Year
            trends_pipeline = [
                {'$addFields': {'year': {'$year': {'$dateFromString': {'dateString': '$dt'}}}}},
                {'$group': {
                    '_id': '$year',
                    'average': {'$avg': '$AverageTemperature'},
                    'min': {'$min': '$AverageTemperature'},
                    'max': {'$max': '$AverageTemperature'},
                    'count': {'$sum': 1}
                }},
                {'$sort': {'_id': 1}},
                {'$project': {
                    'year': '$_id',
                    'average': {'$round': ['$average', 2]},
                    'min': {'$round': ['$min', 2]},
                    'max': {'$round': ['$max', 2]},
                    'count': 1,
                    '_id': 0
                }}
            ]
            trends_results = list(db['country_temps'].aggregate(trends_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'temp_trends_by_year',
                'timestamp': datetime.now(),
                'data': trends_results,
                'record_count': len(trends_results)
            })
            run_metadata['operations'].append('temp_trends_by_year')
            logger.info(f"‚úÖ Stored temp_trends_by_year: {len(trends_results)} records")
            
            # Operation 3: Seasonal Analysis
            seasonal_pipeline = [
                {'$addFields': {'month': {'$month': {'$dateFromString': {'dateString': '$dt'}}}}},
                {'$addFields': {
                    'season': {
                        '$cond': [
                            {'$in': ['$month', [12, 1, 2]]}, 'Winter',
                            {'$cond': [
                                {'$in': ['$month', [3, 4, 5]]}, 'Spring',
                                {'$cond': [
                                    {'$in': ['$month', [6, 7, 8]]}, 'Summer',
                                    'Fall'
                                ]}
                            ]}
                        ]
                    }
                }},
                {'$group': {
                    '_id': '$season',
                    'average': {'$avg': '$AverageTemperature'},
                    'min': {'$min': '$AverageTemperature'},
                    'max': {'$max': '$AverageTemperature'},
                    'count': {'$sum': 1}
                }},
                {'$project': {
                    'season': '$_id',
                    'average': {'$round': ['$average', 2]},
                    'min': {'$round': ['$min', 2]},
                    'max': {'$round': ['$max', 2]},
                    'count': 1,
                    '_id': 0
                }}
            ]
            seasonal_results = list(db['country_temps'].aggregate(seasonal_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'seasonal_analysis',
                'timestamp': datetime.now(),
                'data': seasonal_results,
                'record_count': len(seasonal_results)
            })
            run_metadata['operations'].append('seasonal_analysis')
            logger.info(f"‚úÖ Stored seasonal_analysis: {len(seasonal_results)} records")
            
            # Operation 4: Extreme Temperatures
            extreme_warm = list(db['country_temps'].aggregate([
                {'$sort': {'AverageTemperature': -1}},
                {'$limit': 5},
                {'$addFields': {'type': 'Warmest'}},
                {'$project': {'dt': 1, 'Country': 1, 'AverageTemperature': {'$round': ['$AverageTemperature', 2]}, 'type': 1, '_id': 0}}
            ]))
            extreme_cold = list(db['country_temps'].aggregate([
                {'$sort': {'AverageTemperature': 1}},
                {'$limit': 5},
                {'$addFields': {'type': 'Coldest'}},
                {'$project': {'dt': 1, 'Country': 1, 'AverageTemperature': {'$round': ['$AverageTemperature', 2]}, 'type': 1, '_id': 0}}
            ]))
            extreme_results = extreme_warm + extreme_cold
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'extreme_temps',
                'timestamp': datetime.now(),
                'data': extreme_results,
                'record_count': len(extreme_results)
            })
            run_metadata['operations'].append('extreme_temps')
            logger.info(f"‚úÖ Stored extreme_temps: {len(extreme_results)} records")
            
            # Operation 5: Decade Analysis
            decade_pipeline = [
                {'$addFields': {'year': {'$year': {'$dateFromString': {'dateString': '$dt'}}}}},
                {'$addFields': {'decade': {'$multiply': [{'$floor': {'$divide': ['$year', 10]}}, 10]}}},
                {'$group': {
                    '_id': '$decade',
                    'average': {'$avg': '$AverageTemperature'},
                    'count': {'$sum': 1}
                }},
                {'$sort': {'_id': 1}},
                {'$project': {
                    'decade': '$_id',
                    'average': {'$round': ['$average', 2]},
                    'count': 1,
                    '_id': 0
                }}
            ]
            decade_results = list(db['country_temps'].aggregate(decade_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'decade_analysis',
                'timestamp': datetime.now(),
                'data': decade_results,
                'record_count': len(decade_results)
            })
            run_metadata['operations'].append('decade_analysis')
            logger.info(f"‚úÖ Stored decade_analysis: {len(decade_results)} records")
            
            # Operation 6: Records per Country
            records_pipeline = [
                {'$group': {
                    '_id': '$Country',
                    'record_count': {'$sum': 1}
                }},
                {'$sort': {'record_count': -1}},
                {'$limit': 50},
                {'$project': {
                    'Country': '$_id',
                    'record_count': 1,
                    '_id': 0
                }}
            ]
            records_results = list(db['country_temps'].aggregate(records_pipeline))
            results_collection.insert_one({
                'run_id': run_id,
                'operation': 'records_by_country',
                'timestamp': datetime.now(),
                'data': records_results,
                'record_count': len(records_results)
            })
            run_metadata['operations'].append('records_by_country')
            logger.info(f"‚úÖ Stored records_by_country: {len(records_results)} records")
            
        except Exception as e:
            logger.error(f"Error storing MapReduce results: {e}")
            run_metadata['status'] = 'error'
            run_metadata['error'] = str(e)
        
        # Store run metadata
        db['mapreduce_runs'].insert_one(run_metadata)
        
        logger.info(f"‚úÖ All MapReduce operations completed and stored with ID: {run_id}")
        
        return {
            'message': 'MapReduce operations completed and stored in MongoDB',
            'run_id': run_id,
            'operations': 6,
            'status': 'completed',
            'timestamp': datetime.now().isoformat(),
            'operations_list': run_metadata['operations']
        }

    except Exception as e:
        logger.error(f"MapReduce error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/mapreduce/status')
async def mapreduce_status():
    """Get MapReduce operation status and retrieve latest results"""
    if not mongo_available or db is None:
        return {
            'status': 'completed',
            'operations': 6,
            'completed': 6,
            'failed': 0,
            'timestamp': datetime.now().isoformat()
        }
    
    try:
        # Get latest run
        runs_collection = db['mapreduce_runs']
        latest_run = runs_collection.find_one(sort=[('timestamp', -1)])
        
        if not latest_run:
            return {
                'status': 'no_data',
                'message': 'No MapReduce results found yet. Run operations first.',
                'timestamp': datetime.now().isoformat()
            }
        
        run_id = latest_run['_id']
        results_collection = db['mapreduce_results']
        
        # Retrieve all results for this run
        stored_results = list(results_collection.find({'run_id': run_id}))
        
        return {
            'status': 'completed',
            'run_id': run_id,
            'timestamp': latest_run.get('timestamp', datetime.now()).isoformat(),
            'operations': len(latest_run.get('operations', [])),
            'completed': len(latest_run.get('operations', [])),
            'failed': 0,
            'results_stored': {op['operation']: op['record_count'] for op in stored_results},
            'message': f'Latest MapReduce run stored with {len(stored_results)} result sets'
        }
    
    except Exception as e:
        logger.error(f"Error retrieving MapReduce status: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/mapreduce/results/{operation}')
async def get_mapreduce_result(operation: str):
    """Get stored MapReduce result for a specific operation"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB not available")
    
    try:
        # Get latest run
        runs_collection = db['mapreduce_runs']
        latest_run = runs_collection.find_one(sort=[('timestamp', -1)])
        
        if not latest_run:
            raise HTTPException(status_code=404, detail="No MapReduce results found")
        
        run_id = latest_run['_id']
        results_collection = db['mapreduce_results']
        
        # Retrieve specific operation result
        result = results_collection.find_one({
            'run_id': run_id,
            'operation': operation
        })
        
        if not result:
            raise HTTPException(status_code=404, detail=f"Operation '{operation}' not found in results")
        
        logger.info(f"‚úÖ Retrieved stored result for operation: {operation}")
        return result['data']
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving MapReduce result: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/mapreduce/history')
async def get_mapreduce_history():
    """Get history of all MapReduce runs"""
    if not mongo_available or db is None:
        raise HTTPException(status_code=500, detail="MongoDB not available")
    
    try:
        runs_collection = db['mapreduce_runs']
        
        # Get last 10 runs
        history = list(runs_collection.find().sort('timestamp', -1).limit(10))
        
        # Convert to serializable format
        history_data = []
        for run in history:
            history_data.append({
                'run_id': run['_id'],
                'timestamp': run.get('timestamp', '').isoformat() if hasattr(run.get('timestamp'), 'isoformat') else str(run.get('timestamp')),
                'status': run.get('status', 'unknown'),
                'operations_count': len(run.get('operations', [])),
                'operations': run.get('operations', [])
            })
        
        logger.info(f"‚úÖ Retrieved MapReduce history: {len(history_data)} runs")
        return history_data
    
    except Exception as e:
        logger.error(f"Error retrieving MapReduce history: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# MAIN
# ============================================================================


if __name__ == '__main__':
    logger.info("=" * 70)
    logger.info("üöÄ Climate Analysis FastAPI Server")
    logger.info("=" * 70)
    logger.info(f"Frontend: http://localhost:3000")
    logger.info(f"API: http://localhost:5001")
    logger.info(f"Docs: http://localhost:5001/docs")
    logger.info(f"MongoDB: {'‚úÖ Connected' if mongo_available else '‚ö†Ô∏è  Using Mock Data'}")
    logger.info("=" * 70)
    
    uvicorn.run(app, host="0.0.0.0", port=5001, reload=False, log_level="info")

